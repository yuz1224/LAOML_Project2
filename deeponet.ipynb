{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `DeepONet` class\n",
    "\n",
    "In the following code block, you can find a template for the class `DeepONet` that implements the DeepONet architecture from [1] (see project description). In particular, the architecture is of the form\n",
    "$$\n",
    "\t{\\rm DeepONet}(a,b,x,y) = \\sum_{i=1}^{N} B_i (a,b) \\, T_i (x,y),\n",
    "$$\n",
    "with the \"Branch Net\" $B (a,b)$ and the \"Trunk Net\" $T (x,y)$ being feedforward neural networks; $N$ is a hyper parameter, which is related to the complexity of the model. Therefore, the class `DeepONet` should rely on the previously implemented class `FeedforwardNeuralNetwork`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepONet:\n",
    "    def __init__(self, branch_layer_sizes, trunk_layer_sizes):\n",
    "        \"\"\"\n",
    "        Initialize the DeepONet architecture.\n",
    "        \n",
    "        Parameters:\n",
    "        branch_layer_sizes (list): List containing the number of neurons in each layer for the branch net.\n",
    "        trunk_layer_sizes (list): List containing the number of neurons in each layer for the trunk net.\n",
    "        \"\"\"\n",
    "        self.branch_net = FeedforwardNeuralNetwork(branch_layer_sizes)\n",
    "        self.trunk_net = FeedforwardNeuralNetwork(trunk_layer_sizes)\n",
    "        \n",
    "        # Ensure the output dimensions of the branch and trunk nets match\n",
    "        assert branch_layer_sizes[-1] == trunk_layer_sizes[-1], \"Output dimensions of branch and trunk nets must match\"\n",
    "\n",
    "    def feedforward(self, x_branch, x_trunk):\n",
    "        \"\"\"\n",
    "        Perform a feedforward pass through the DeepONet.\n",
    "        \n",
    "        Parameters:\n",
    "        x_branch (numpy.ndarray): Input array for the branch net.\n",
    "        x_trunk (numpy.ndarray): Input array for the trunk net.\n",
    "        \n",
    "        Returns:\n",
    "        numpy.ndarray: Output of the DeepONet.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Insert missing code!\n",
    "\n",
    "    def compute_cost(self, y_pred, y_train):\n",
    "        \"\"\"\n",
    "        Compute the cost function.\n",
    "        \n",
    "        Parameters:\n",
    "        y_pred (numpy.ndarray): Predicted labels.\n",
    "        y_train (numpy.ndarray): True labels.\n",
    "        \n",
    "        Returns:\n",
    "        float: Cost value.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Insert missing code!\n",
    "\n",
    "    def backpropagate(self, x_branch, x_trunk, y):\n",
    "        \"\"\"\n",
    "        Perform backpropagation to compute gradients.\n",
    "        \n",
    "        Parameters:\n",
    "        x_branch (numpy.ndarray): Input array for the branch net.\n",
    "        x_trunk (numpy.ndarray): Input array for the trunk net.\n",
    "        y (numpy.ndarray): True labels.\n",
    "        \n",
    "        Returns:\n",
    "        tuple: Gradients of weights and biases for both branch and trunk nets.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Insert missing code!\n",
    "        \n",
    "    def update_parameters(self, nabla_w_branch, nabla_b_branch, nabla_w_trunk, nabla_b_trunk, learning_rate):\n",
    "        \"\"\"\n",
    "        Update the weights and biases using the computed gradients.\n",
    "        \n",
    "        Parameters:\n",
    "        nabla_w_branch (list): Gradients of weights for the branch net.\n",
    "        nabla_b_branch (list): Gradients of biases for the branch net.\n",
    "        nabla_w_trunk (list): Gradients of weights for the trunk net.\n",
    "        nabla_b_trunk (list): Gradients of biases for the trunk net.\n",
    "        learning_rate (float): Learning rate.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Insert missing code!\n",
    "\n",
    "    def train(self, x_branch, x_trunk, y_train, epochs, learning_rate, batch_size):\n",
    "        \"\"\"\n",
    "        Train the DeepONet using mini-batch gradient descent optimization with early stopping.\n",
    "        \n",
    "        Parameters:\n",
    "        x_branch (numpy.ndarray): Training data for the branch net.\n",
    "        x_trunk (numpy.ndarray): Training data for the trunk net.\n",
    "        y_train (numpy.ndarray): Training labels.\n",
    "        epochs (int): Number of epochs.\n",
    "        learning_rate (float): Learning rate.\n",
    "        batch_size (int): Size of each mini-batch.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Insert missing code!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
